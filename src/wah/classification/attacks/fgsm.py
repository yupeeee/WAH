import torch
from torch import nn

from ...typing import Device, Module, Optional, Tensor

__all__ = [
    "FGSM",
    "IFGSM",
]


class IFGSM:
    """
    [Iterative Fast Gradient Sign Method (IFGSM)](https://openreview.net/forum?id=BJm4T4Kgx) for generating adversarial examples.

    ### Attributes
    - `model` (Module): The model to attack, in evaluation mode.
    - `epsilon` (float): The maximum allowed perturbation.
    - `iteration` (int): The number of iterations for the attack.
    - `alpha` (float): The step size for each iteration.
    - `device` (Device): The device to use for computation.

    ### Methods
    - `__call__(data: Tensor, targets: Tensor) -> Tensor`: Generates adversarial examples by iteratively applying the FGSM attack.
    - `grad(data: Tensor, targets: Tensor) -> Tensor`: Computes the gradient of the loss with respect to the input data.
    - `_fgsm(data: Tensor, targets: Tensor, epsilon: float) -> Tensor`: Performs a single step of the FGSM attack.
    """

    def __init__(
        self,
        model: Module,
        epsilon: float,
        iteration: int,
        alpha: Optional[float] = None,
        device: Optional[Device] = "cpu",
    ) -> None:
        """
        - `model` (Module): The model to attack.
        - `epsilon` (float): The maximum perturbation that can be added to the input.
        - `iteration` (int): The number of iterations for the attack.
        - `alpha` (float, optional): The step size for each iteration. If not provided, defaults to `epsilon / iteration`.
        - `device` (Device, optional): The device to use for computation. Defaults to `"cpu"`.
        """
        self.model = model.eval()
        self.epsilon = epsilon
        self.iteration = iteration
        self.alpha = epsilon / iteration if alpha is None else alpha
        self.device = torch.device(device)

        self.criterion = nn.CrossEntropyLoss()

    def __call__(
        self,
        data: Tensor,
        targets: Tensor,
    ) -> Tensor:
        """
        Generates adversarial examples by iteratively applying the FGSM attack.

        ### Parameters
        - `data` (Tensor): The input data to be perturbed.
        - `targets` (Tensor): The target labels for the input data.

        ### Returns
        - `Tensor`: The adversarial examples generated by perturbing the input data.
        """
        if self.epsilon == 0.0:
            return data

        _data = data.detach()

        for _ in range(self.iteration):
            _data = self._fgsm(_data, targets, self.alpha)

        return _data.to(torch.device("cpu"))

    def grad(
        self,
        data: Tensor,
        targets: Tensor,
    ) -> Tensor:
        """
        Computes the gradient of the loss with respect to the input data.

        ### Parameters
        - `data` (Tensor): The input data.
        - `targets` (Tensor): The target labels.

        ### Returns
        - `Tensor`: The gradient of the loss with respect to the input data.
        """
        data = data.to(self.device)
        targets = targets.to(self.device)

        data = data.detach()
        data.requires_grad = True

        outputs = self.model(data)
        self.model.zero_grad()
        loss: Tensor = self.criterion(outputs, targets)
        loss.backward()

        with torch.no_grad():
            grads = data.grad.data

        return grads.detach()

    def _fgsm(
        self,
        data: Tensor,
        targets: Tensor,
        epsilon: float,
    ) -> Tensor:
        """
        Performs a single step of the FGSM attack.

        ### Parameters
        - `data` (Tensor): The input data.
        - `targets` (Tensor): The target labels.
        - `epsilon` (float): The step size for the attack.

        ### Returns
        - `Tensor`: The perturbed input data after one FGSM step.
        """
        if epsilon == 0.0:
            return data

        signed_grads = -self.grad(data, targets).sign()

        perturbations = epsilon * signed_grads
        perturbations = perturbations.clamp(-epsilon, epsilon)

        _data = data + perturbations
        _data = _data.clamp(0, 1)

        return _data


class FGSM(IFGSM):
    """
    [Fast Gradient Sign Method (FGSM)](https://arxiv.org/abs/1412.6572) for generating adversarial examples.

    ### Attributes
    - `model` (Module): The model to attack.
    - `epsilon` (float): The maximum perturbation for a single-step attack.
    - `device` (Device): The device to use for computation.

    ### Methods
    - `__call__(data: Tensor, targets: Tensor) -> Tensor`: Generates adversarial examples using a single FGSM attack step.
    """

    def __init__(
        self,
        model: Module,
        epsilon: float,
        device: Optional[Device] = "cpu",
    ) -> None:
        """
        - `model` (Module): The model to attack.
        - `epsilon` (float): The maximum perturbation that can be added to the input in a single step.
        - `device` (Device, optional): The device to use for computation. Defaults to `"cpu"`.
        """
        super().__init__(model, epsilon, 1, None, device)
